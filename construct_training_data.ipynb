{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "346e2243-07e9-49c8-a1bf-bc1c6eacf599",
   "metadata": {},
   "source": [
    "# Construct training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eebcaea-cbd6-4798-90c1-b0d782d389e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raineyaberle/opt/anaconda3/envs/snowmal/lib/python3.12/site-packages/pyproj/__init__.py:89: UserWarning: pyproj unable to set database path.\n",
      "  _pyproj_global_context_initialize()\n",
      "/Users/raineyaberle/opt/anaconda3/envs/snowmal/lib/python3.12/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "import numpy as np\n",
    "import xrspatial\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c3488-c5bf-46f0-a9b1-4c5a07f8cec5",
   "metadata": {},
   "source": [
    "## Define paths to inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c26c6-9f2c-4442-b17d-badc1188c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site info used for output file names\n",
    "site_name = 'MCS'\n",
    "date = '2024-03-15'\n",
    "\n",
    "# Path where output training data will be saved\n",
    "out_dir = '/Volumes/LaCie/raineyaberle/Research/PhD/SnowMaL/study-sites/MCS/'\n",
    "out_fn = os.path.join(out_dir, f'{site_name}_{date}_training_data.csv')\n",
    "# Reference DEM\n",
    "refdem_fn = '/Volumes/LaCie/raineyaberle/Research/PhD/Skysat-Stereo/study-sites/MCS/refdem/MCS_REFDEM_WGS84.tif'\n",
    "# Snow depth map\n",
    "sd_fn = '/Volumes/LaCie/raineyaberle/Research/PhD/Skysat-Stereo/study-sites/MCS/lidar/20240315_MCS-snowdepth_RF_5m.tif'\n",
    "# SNOTEL data and site info\n",
    "snotel_fn = '/Volumes/LaCie/raineyaberle/Research/PhD/Skysat-Stereo/study-sites/MCS/snotel/MCS_2020-01-01_2024-06-07_adj.csv'\n",
    "snotel_info_fn = '/Volumes/LaCie/raineyaberle/Research/PhD/Skysat-Stereo/study-sites/MCS/snotel/MCS_SNOTEL_site_info.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6de4fc-3c24-4ae8-baa0-4faf0becd5f0",
   "metadata": {},
   "source": [
    "## Load inputs and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936628f2-638f-4f15-a834-d88ad4b8dfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Snow depth map\n",
    "sd = xr.open_dataset(sd_fn).squeeze()\n",
    "sd = sd.rename({'band_data': 'snow_depth_m'})\n",
    "\n",
    "# -----Reference DEM\n",
    "refdem = xr.open_dataset(refdem_fn).squeeze()\n",
    "refdem_crs = refdem.rio.crs.to_epsg()\n",
    "# Replace no data values with NaNs\n",
    "refdem = xr.where(refdem <= -1e38, np.nan, refdem)\n",
    "# Interpolate at snow depth map coordinates\n",
    "refdem = refdem.interp(x=sd.x.data, y=sd.y.data)\n",
    "# Calculate slope and aspect\n",
    "refdem = refdem.rename({'band_data': 'elevation'})\n",
    "refdem['slope'] = xrspatial.slope(refdem.elevation)\n",
    "refdem['aspect'] = xrspatial.aspect(refdem.elevation)\n",
    "# Add snow depth as band\n",
    "refdem['snow_depth_m'] = sd.snow_depth_m\n",
    "refdem = refdem.rio.write_crs(f'EPSG:{refdem_crs}')\n",
    "\n",
    "# -----SNOTEL\n",
    "snotel = pd.read_csv(snotel_fn)\n",
    "snotel['datetime'] = pd.to_datetime(snotel['datetime'])\n",
    "snotel['datetime'] = [x.replace(tzinfo=None) for x in snotel['datetime']] \n",
    "# Calculate PDDs using average daily temperature\n",
    "snotel['PDD'] = [x if x > 0 else 0 for x in snotel['TAVG_C']]\n",
    "# Calculate cumulative sum of PDDs by water year\n",
    "snotel['water_year'] = snotel['datetime'].apply(lambda x: x.year + 1 if x.month >= 10 else x.year)\n",
    "snotel['PDD_cumsum'] = snotel.groupby('water_year')['PDD'].cumsum()\n",
    "# Grab SNOTEL values on snow depth date\n",
    "sd_dt = datetime.datetime(int(sd_date[0:4]), int(sd_date[5:7]), int(sd_date[8:]))\n",
    "snotel_date = snotel.loc[snotel['datetime']==sd_dt]\n",
    "# Grab site coordinates\n",
    "snotel_info = pd.read_csv(snotel_info_fn)\n",
    "snotel_info['geometry'] = snotel_info['geometry'].apply(wkt.loads)\n",
    "snotel_info = gpd.GeoDataFrame(snotel_info, geometry='geometry', crs='EPSG:4326')\n",
    "snotel_info = snotel_info.to_crs(f'EPSG:{sd.rio.crs.to_epsg()}')\n",
    "# Sample terrain info at SNOTEL coordinates\n",
    "refdem_snotel = refdem.sel(x=snotel_info.geometry[0].coords.xy[0][0], y=snotel_info.geometry[0].coords.xy[1][0], method='nearest')\n",
    "snotel_date['elevation'] = float(refdem_snotel.elevation.data)\n",
    "snotel_date['slope'] = float(refdem_snotel.slope.data)\n",
    "snotel_date['aspect'] = float(refdem_snotel.aspect.data)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10,12))\n",
    "ax = ax.flatten()\n",
    "columns = ['snow_depth_m', 'elevation', 'slope', 'aspect']\n",
    "labels = ['Snow depth [m]', 'Elevation [m]', 'Slope [degrees]', 'Aspect [degrees]']\n",
    "cmaps = ['Blues', 'terrain', 'Greens', 'twilight']\n",
    "for i in range(len(columns)):\n",
    "    im = ax[i].imshow(refdem[columns[i]].data, cmap=cmaps[i],\n",
    "                  extent=(np.min(refdem.x.data)/1e3, np.max(refdem.x.data)/1e3, \n",
    "                          np.min(refdem.y.data)/1e3, np.max(refdem.y.data)/1e3))\n",
    "    fig.colorbar(im, ax=ax[i], label=labels[i], orientation='horizontal', shrink=0.8)\n",
    "    ax[i].plot(snotel_info['geometry'].values[0].coords.xy[0][0] / 1e3, \n",
    "               snotel_info['geometry'].values[0].coords.xy[1][0] / 1e3, '*m')\n",
    "for axis in [ax[2], ax[3]]:\n",
    "    axis.set_xlabel('Easting [km]')\n",
    "for axis in [ax[0], ax[2]]:\n",
    "    axis.set_ylabel('Northing [km]')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ad1c96-9115-43b1-ab1a-8ea804b97205",
   "metadata": {},
   "source": [
    "## Construct the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a3eedf-9c98-4cdd-9b0c-39adaad6eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference DEM and snow depth data\n",
    "training_data_df = pd.DataFrame()\n",
    "for column in ['elevation', 'slope', 'aspect', 'snow_depth_m']:\n",
    "    df = pd.DataFrame({column: np.ravel(refdem.elevation.data)})\n",
    "    training_data_df = pd.concat([training_data_df, df], axis=1)\n",
    "\n",
    "# SNOTEL data\n",
    "training_data_df['SNOTEL_snow_depth'] = snotel_date['SNWD_m'].values[0]\n",
    "training_data_df['SNOTEL_SWE'] = snotel_date['SWE_m'].values[0]\n",
    "training_data_df['SNOTEL_pdd_cumsum'] = snotel_date['PDD_cumsum'].values[0]\n",
    "training_data_df['SNOTEL_elevation'] = snotel_date['elevation'].values[0]\n",
    "training_data_df['SNOTEL_slope'] = snotel_date['slope'].values[0]\n",
    "training_data_df['SNOTEL_aspect'] = snotel_date['aspect'].values[0]\n",
    "\n",
    "training_data_df.dropna(inplace=True)\n",
    "training_data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Convert terrain values to ints to save on memory\n",
    "for col in training_data_df.columns:\n",
    "    if ('elevation' in col) or ('slope' in col) or ('aspect' in col):\n",
    "        training_data_df[col] = training_data_df[col].astype(int)\n",
    "\n",
    "# Save to file\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "training_data_df.to_csv(out_fn, index=False)\n",
    "print('Training data saved to file:', out_fn)\n",
    "\n",
    "training_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868d168d-598d-4548-add5-836dfbd17829",
   "metadata": {},
   "source": [
    "## Plot pairplot of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3062a1e-861e-4e60-9f8f-31ae0a965fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowmal",
   "language": "python",
   "name": "snowmal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
