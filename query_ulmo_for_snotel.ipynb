{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2593687-1e6f-4931-9443-7d94befa1f25",
   "metadata": {},
   "source": [
    "# Query the CUAHSI Hydroportal for SNOTEL data\n",
    "\n",
    "Adapted from the [2021 SnowEX Hackweek tutorial by David Shean](https://snowex-2021.hackweek.io/tutorials/geospatial/SNOTEL_query.html)\n",
    "\n",
    "__Note: this notebook (specifically the `ulmo` package) requires a different version of Python than the other notebooks that use `XDEM`, so I ran this using a separate `mamba` environment.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb891c-ea09-448e-827f-a5d1d5306f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import ulmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c418113-a37b-4696-b232-ca572e03878f",
   "metadata": {},
   "source": [
    "## Define paths to data and variables to fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a95c3-e942-4a1a-8692-903fef2c7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths in directory\n",
    "site_name = 'MCS'\n",
    "data_path = f'/Volumes/LaCie/raineyaberle/Research/PhD/SkySat-Stereo/study-sites'\n",
    "out_dir = os.path.join(data_path, site_name, 'snotel')\n",
    "aoi_fn = glob.glob(os.path.join(data_path, site_name, 'AOIs', f'*bounds*.shp'))[0]\n",
    "\n",
    "fetch_vars = ['SNOTEL:PRCPSA_D', 'SNOTEL:SNWD_D', 'SNOTEL:TAVG_D', 'SNOTEL:TMAX_D', 'SNOTEL:TMIN_D', 'SNOTEL:TOBS_D', 'SNOTEL:WTEQ_D']\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-06-07'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d5edf-5de4-4924-ac4a-9311b7f79373",
   "metadata": {},
   "source": [
    "## Load Snotel sites from CUAHSI Hydroshare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111cc06f-5062-4737-8f53-a0cf2ccc982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsdlurl = 'https://hydroportal.cuahsi.org/Snotel/cuahsi_1_1.asmx?WSDL'\n",
    "sites = ulmo.cuahsi.wof.get_sites(wsdlurl)\n",
    "\n",
    "# Adjust variables\n",
    "sites_df = pd.DataFrame.from_dict(sites, orient='index').dropna()\n",
    "sites_df['geometry'] = [Point(float(loc['longitude']), float(loc['latitude'])) for loc in sites_df['location']]\n",
    "sites_df = sites_df.drop(columns='location')\n",
    "sites_df = sites_df.astype({\"elevation_m\":float})\n",
    "\n",
    "# Convert to geopandas.GeoDataFrame\n",
    "sites_gdf = gpd.GeoDataFrame(sites_df, crs='EPSG:4326')\n",
    "sites_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d36960f-525b-46c5-8c76-b8d19901eff4",
   "metadata": {},
   "source": [
    "## Filter SNOTEL sites by AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648a9087-a180-4c4a-8370-bc75fe6ea595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load site bounds\n",
    "aoi = gpd.read_file(aoi_fn)\n",
    "aoi = aoi.to_crs('EPSG:4326')\n",
    "\n",
    "# Filter SNOTEL sits using site bounds\n",
    "sites_filt_gdf = sites_gdf.loc[sites_gdf.intersects(aoi.geometry[0])]\n",
    "site_code = sites_filt_gdf['code'].index[-1]\n",
    "print(f'Site code: {site_code}')\n",
    "\n",
    "# Plot AOI and SNOTEL site location(s)\n",
    "fig, ax = plt.subplots()\n",
    "aoi.plot(ax=ax, facecolor='None', edgecolor='c')\n",
    "sites_filt_gdf.plot(ax=ax, color='b')\n",
    "plt.show()\n",
    "\n",
    "# Save site information to file\n",
    "site_fn = os.path.join(out_dir, f'{site_name}_SNOTEL_site_info.csv')\n",
    "sites_filt_df = pd.DataFrame(sites_filt_gdf)\n",
    "sites_filt_df.to_csv(site_fn)\n",
    "print('Site info saved to file:', site_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d404b248-57d9-4fb5-bf6a-b8b55d12b154",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Option to check variables available at site\n",
    "var_info = ulmo.cuahsi.wof.get_site_info(wsdlurl, sites_filt_gdf['code'].index[0])\n",
    "var_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cc850b-2f94-4823-bdf0-fab4c981117d",
   "metadata": {},
   "source": [
    "## Fetch data, save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def82f8-7ad1-4797-97ed-4e646c14c86b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def snotel_fetch(sitecode, variablecode='SNOTEL:SNWD_D', \n",
    "                 start_date='1950-10-01', end_date=datetime.today().strftime('%Y-%m-%d')):\n",
    "    #print(sitecode, variablecode, start_date, end_date)\n",
    "    values_df = None\n",
    "    try:\n",
    "        # Request data from the server\n",
    "        site_values = ulmo.cuahsi.wof.get_values(wsdlurl, sitecode, variablecode, start=start_date, end=end_date)\n",
    "        # Convert to a Pandas DataFrame   \n",
    "        values_df = pd.DataFrame.from_dict(site_values['values'])\n",
    "        # Parse the datetime values to Pandas Timestamp objects\n",
    "        values_df['datetime'] = pd.to_datetime(values_df['datetime'], utc=True)\n",
    "        # Set the DataFrame index to the Timestamps\n",
    "        values_df = values_df.set_index('datetime')\n",
    "        # Convert values to float and replace -9999 nodata values with NaN\n",
    "        values_df['value'] = pd.to_numeric(values_df['value']).replace(-9999, np.nan)\n",
    "        # Remove any records flagged with lower quality\n",
    "        values_df = values_df[values_df['quality_control_level_code'] == '1']\n",
    "    except:\n",
    "        print(\"Unable to fetch %s\" % variablecode)\n",
    "\n",
    "    return values_df\n",
    "\n",
    "# Check if output directory exists\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "    print('Made directory for outputs:', out_dir)\n",
    "\n",
    "# Iterate over variables\n",
    "for var in fetch_vars:\n",
    "    # Define output file name\n",
    "    out_fn = os.path.join(out_dir, f\"{site_name}_{start_date}_{end_date}_{var.replace(':','_')}.csv\")\n",
    "    # Fetch data\n",
    "    values_df = snotel_fetch(site_code, var, start_date, end_date)\n",
    "    values_df['variable'] = var\n",
    "    # Plot variable\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(values_df.index, values_df['value'])\n",
    "    plt.ylabel(var)\n",
    "    plt.show()\n",
    "    # Save to file\n",
    "    values_df.to_csv(out_fn, index=True)\n",
    "    print('Data saved to file:', out_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c517929-c007-4492-b5f5-fd87962da00a",
   "metadata": {},
   "source": [
    "## Adjust dataframe and variable units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ddf56-b46e-4467-b615-d4a0102b239d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fns = sorted(glob.glob(os.path.join(out_dir, f\"{site_name}_{start_date}_{end_date}_SNO*.csv\")))\n",
    "\n",
    "for i, fn in enumerate(out_fns):\n",
    "    df = pd.read_csv(fn)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    if 'PRCPSA' in os.path.basename(fn):\n",
    "        df = df.rename(columns={'value': 'PRCPSA_in'})\n",
    "        df['PRCPSA_m'] = df['PRCPSA_in'] / 39.37\n",
    "        df = df['PRCPSA_m']\n",
    "    elif 'SNWD' in os.path.basename(fn):\n",
    "        df = df.rename(columns={'value': 'SNWD_in'})\n",
    "        df['SNWD_m'] = df['SNWD_in'] / 39.37\n",
    "        df = df['SNWD_m']\n",
    "    elif 'TAVG' in os.path.basename(fn):\n",
    "        df = df.rename(columns={'value': 'TAVG_F'})\n",
    "        df['TAVG_C'] = (df['TAVG_F'] - 32) *5 / 9\n",
    "        df = df['TAVG_C']\n",
    "    elif 'TMAX' in os.path.basename(fn):\n",
    "        df = df.rename(columns={'value': 'TMAX_F'})\n",
    "        df['TMAX_C'] = (df['TMAX_F'] - 32) *5 / 9\n",
    "        df = df['TMAX_C']\n",
    "    elif 'TMIN' in os.path.basename(fn):\n",
    "        df = df.rename(columns={'value': 'TMIN_F'})\n",
    "        df['TMIN_C'] = (df['TMIN_F'] - 32) *5 / 9\n",
    "        df = df['TMIN_C']\n",
    "    elif 'TOBS' in os.path.basename(fn):\n",
    "        df = df.rename(columns={'value': 'TOBS_F'})\n",
    "        df['TOBS_C'] = (df['TOBS_F'] - 32) *5 / 9\n",
    "        df = df['TOBS_C']\n",
    "    elif 'WTEQ' in os.path.basename(fn):\n",
    "        df = df.rename(columns={'value': 'SWE_in'})\n",
    "        df['SWE_m'] = df['SWE_in'] / 39.37\n",
    "        df = df['SWE_m']\n",
    "    df = pd.DataFrame(df)\n",
    "\n",
    "    if i==0:\n",
    "        df_full = df\n",
    "    else:\n",
    "        df_full = df_full.merge(df, on='datetime')\n",
    "\n",
    "# Save to file\n",
    "df_fn = os.path.join(out_dir, f\"{site_name}_{start_date}_{end_date}_adj.csv\")\n",
    "df_full.to_csv(df_fn, index=True)\n",
    "print('Adjusted data table saved to file:', df_fn)\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0cdf1-fef8-40a3-a907-b3040987e89a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ulmo",
   "language": "python",
   "name": "ulmo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
